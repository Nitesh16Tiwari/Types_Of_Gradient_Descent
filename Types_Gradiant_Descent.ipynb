{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b225edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sma\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26a885a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Inbuild DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75e6f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ed82e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42410375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.002592  0.019907 -0.017646  \n",
       "1   -0.039493 -0.068332 -0.092204  \n",
       "2   -0.002592  0.002861 -0.025930  \n",
       "3    0.034309  0.022688 -0.009362  \n",
       "4   -0.002592 -0.031988 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018114  0.044485  \n",
       "439 -0.011080 -0.046883  0.015491  \n",
       "440  0.026560  0.044529 -0.025930  \n",
       "441 -0.039493 -0.004222  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9618372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e73d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.8,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f1911dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10)\n",
      "(89, 10)\n",
      "(353,)\n",
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15fbc6b",
   "metadata": {},
   "source": [
    "# Batch Gradiant Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd95cc0",
   "metadata": {},
   "source": [
    "* It is an iteravtive algorithm that updates models parameters after processing the entire dataset.\n",
    "\n",
    "* We take the average of gradients of all the training examples and then use that mean gradient to update our parameters .\n",
    "\n",
    "* One step of GD in one epoch ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86424d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f8bc9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8337d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238]\n",
      "151.88331005254167\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6c35a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399338661568969"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(x_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "018d58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check with our own function class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5115c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_=None\n",
    "        self.intercept_=None\n",
    "        self.l_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,x_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(x_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            # Update all the coef and the intercept\n",
    "            y_hat = np.dot(x_train,self.coef_) + self.intercept_\n",
    "            # print('shape of y_hat',y_hat.shape)\n",
    "            intercept_der = -2 * np.mean(y_train - y_hat)\n",
    "            self.intercept_ = self.intercept_ - ( self.l_rate * intercept_der)\n",
    "            \n",
    "            coef_der = -2 * np.dot((y_train - y_hat),x_train) / x_train.shape[0]\n",
    "            self.coef_ = self.coef_ - (self.l_rate * coef_der)\n",
    "            \n",
    "        print(self.intercept_,self.coef_)\n",
    "        \n",
    "    def predict(self,x_test):\n",
    "        return np.dot(x_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d04e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdr = GDRegressor(epochs=1000000,learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba2e2d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.8833100525583 [  -9.15865318 -205.45432162  516.69374457  340.61999904 -895.55200041\n",
      "  561.22067786  153.89310887  126.73139669  861.12700097   52.42112238]\n"
     ]
    }
   ],
   "source": [
    "gdr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "590414da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gdr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ed194d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43993386616830465"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57391f",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278e32a",
   "metadata": {},
   "source": [
    "**Stochastic Gradient Descent (SGD) is an optimization algorithm used to train machine learning models, particularly in scenarios with large datasets. Unlike batch gradient descent, which computes gradients for the entire dataset in each iteration, SGD updates the model's parameters using only a single randomly chosen data point at a time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a3c508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c59025c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(max_iter=100,learning_rate='constant',eta0=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be8f2c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(eta0=0.2, learning_rate=&#x27;constant&#x27;, max_iter=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(eta0=0.2, learning_rate=&#x27;constant&#x27;, max_iter=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor(eta0=0.2, learning_rate='constant', max_iter=100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ea755c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ed63d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4351558866834837"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "feea616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check with our own function class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aa73ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDregressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_=None\n",
    "        self.intercept_=None\n",
    "        self.l_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,x_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(x_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(x_train.shape[0]):\n",
    "                idx = np.random.randint(0,x_train.shape[0])\n",
    "                \n",
    "                # Update all the coef and the intercept\n",
    "                y_hat = np.dot(x_train[idx],self.coef_) + self.intercept_\n",
    "                \n",
    "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - ( self.l_rate * intercept_der)\n",
    "                \n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),x_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.l_rate * coef_der)\n",
    "            \n",
    "        print(self.intercept_,self.coef_)\n",
    "            \n",
    "    def predict(self,x_test):\n",
    "        return np.dot(x_test,self.coef_) + self.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45f8d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDregressor(learning_rate=0.01,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0e18cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.78721874422 [  56.10564576  -64.78165961  350.554937    253.37022814   17.67730218\n",
      "  -32.32881309 -170.05380257  125.52108471  329.4457835   126.62044156]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sgdr.fit(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97dcf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgdr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "06c95457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4313414225885501"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd88bf3",
   "metadata": {},
   "source": [
    "# Mini Batch Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8691653",
   "metadata": {},
   "source": [
    "**It means dividing your dataset into smaller parts (mini-batches), working on these smaller parts one at a time, calculating how wrong your model's predictions are (loss), and adjusting the model's parameters (weights) to improve the predictions. This process repeats until the model gets better at making predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fbae5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do first with the inbulid function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "52e681dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eff0e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(learning_rate='constant',eta0=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2afdae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 35\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    idx = random.sample(range(x_train.shape[0]),batch_size)\n",
    "    sgd.partial_fit(x_train[idx],y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ed802104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  42.24255968,  -67.35305159,  341.81697617,  228.98833855,\n",
       "         22.14860478,  -25.44312832, -172.28416166,  132.35880867,\n",
       "        319.69069389,  107.66370809])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "78bdee22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159.05991239])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0a0c7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ae004199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4249340284376648"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6ff6bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try with our class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f99dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBSGDregressor:\n",
    "    \n",
    "    def __init__(self,batch_size,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_=None\n",
    "        self.intercept_=None\n",
    "        self.l_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "    def fit(self,x_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(x_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(int(x_train.shape[0]/self.batch_size)):\n",
    "                           \n",
    "                idx = random.sample(range(x_train.shape[0]),self.batch_size)\n",
    "                \n",
    "                # Update all the coef and the intercept\n",
    "                y_hat = np.dot(x_train[idx],self.coef_) + self.intercept_\n",
    "                \n",
    "                intercept_der = -2 * np.mean(y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - ( self.l_rate * intercept_der)\n",
    "                \n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),x_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.l_rate * coef_der)\n",
    "            \n",
    "        print(self.intercept_,self.coef_)\n",
    "            \n",
    "    def predict(self,x_test):\n",
    "        return np.dot(x_test,self.coef_) + self.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2a47fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbg = MBSGDregressor(batch_size=int(x_train.shape[0]/35),learning_rate=0.1,epochs=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "17b8679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.86083250822938 [  11.37045834 -204.57315614  537.58692344  319.94901001 -111.64712585\n",
      "  -41.7958552  -176.45402241   58.32614835  539.56482733   57.09491286]\n"
     ]
    }
   ],
   "source": [
    "mbg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "58fe192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11.37045834, -204.57315614,  537.58692344,  319.94901001,\n",
       "       -111.64712585,  -41.7958552 , -176.45402241,   58.32614835,\n",
       "        539.56482733,   57.09491286])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "0528e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.86083250822938"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "58005b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mbg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9c790420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42729599044775257"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502dba4b",
   "metadata": {},
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
